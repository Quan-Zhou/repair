{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'humancompatible'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhumancompatible\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrepair\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmethods\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rdata_analysis\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     14\u001b[0m path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mgetcwd())\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'humancompatible'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover,Reweighing,LFR\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import CompasDataset\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from humancompatible.repair.methods.data_analysis import rdata_analysis\n",
    "\n",
    "import os\n",
    "path=os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baselinepreprocess:\n",
    "    \"\"\"\n",
    "    A class to evaluate fairness and performance of 3 bias mitigation methods\n",
    "    in the AIF360 documentation:https://aif360.readthedocs.io/en/latest/modules/algorithms.html.\n",
    "\n",
    "    This class supports methods like Reweighing, Disparate Impact Remover, and LFR (Learning fair representations)\n",
    "    to preprocess data, train models, and assess fairness metrics of \n",
    "    Disparate Impact and F1 scores.\n",
    "\n",
    "    Parameters:\n",
    "        train, test (aif360.datasets.BinaryLabelDataset): The dataset to be evaluated.\n",
    "        pa (str): The name of the protected attribute (e.g., 'sex', 'race').\n",
    "   \n",
    "    Methods:\n",
    "        preprocessing(method): Preprocess the dataset using the specified method.\n",
    "        prediction(method): Predict outcomes using a random forest on the test data.\n",
    "        assess(method): Compute performance and fairness metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,train,test):\n",
    "        self.train = train \n",
    "        self.test = test\n",
    "        self.pa = train.protected_attribute_names[0]\n",
    "        self.pa_index = train.feature_names.index(self.pa)\n",
    "        self.prigroups = [{self.pa: 1}]\n",
    "        self.unprigroups = [{self.pa: 0}]\n",
    "\n",
    "    def preprocessing(self,method):\n",
    "        \"\"\"\n",
    "        Preprocess training and/or test data for a given fairness method.\n",
    "\n",
    "        Applies preprocessing steps as described in the AIF360 documentation:\n",
    "        https://aif360.readthedocs.io/en/latest/modules/algorithms.html\n",
    "\n",
    "        Parameters:\n",
    "            methods (str): The name of the method to evaluate.\n",
    "                        Must be one of ['origin', 'RW', 'DIremover', 'LFR'].\n",
    "\n",
    "        Returns:\n",
    "            aif360.datasets.BinaryLabelDataset: The processed training and test data.\n",
    "        \"\"\"\n",
    "        test_tranf = self.test.copy()\n",
    "        if method == 'RW':\n",
    "            RW = Reweighing(privileged_groups = self.prigroups,\n",
    "                            unprivileged_groups = self.unprigroups)\n",
    "            RW.fit(self.train)\n",
    "            train_tranf = RW.transform(self.train)\n",
    "        elif method == 'DIremover':\n",
    "            di = DisparateImpactRemover(repair_level = 1,\n",
    "                                        sensitive_attribute=self.pa)\n",
    "            train_tranf = di.fit_transform(self.train)\n",
    "            test_tranf = di.fit_transform(self.test)\n",
    "        elif method == 'LFR':\n",
    "            TR = LFR(privileged_groups = self.prigroups,\n",
    "                     unprivileged_groups = self.unprigroups,\n",
    "                     Az = 1, Ax = 0.01, Ay = 1,verbose=0)\n",
    "            TR = TR.fit(self.train)\n",
    "            train_tranf = TR.transform(self.train)\n",
    "            test_tranf = TR.transform(self.test)\n",
    "        return train_tranf, test_tranf\n",
    "\n",
    "    def prediction(self,method):\n",
    "        \"\"\"\n",
    "        Predict outcomes using a random forest classifier with a given fairness method.\n",
    "\n",
    "        Parameters:\n",
    "            methods (str): The name of the method to evaluate.\n",
    "                        Must be one of ['origin', 'RW', 'DIremover', 'LFR'].\n",
    "\n",
    "        Returns:\n",
    "            y_pred (aif360.datasets.BinaryLabelDataset): Predictions on the test data.\n",
    "            di (float): Disparate Impact computed on the (processed) training data.\n",
    "        \"\"\"\n",
    "        test_tranf = self.test.copy()\n",
    "        if method == 'origin':\n",
    "            train_tranf = self.train\n",
    "        elif method in ['RW','DIremover','LFR','OP']:\n",
    "            train_tranf,test_tranf = self.preprocessing(method)\n",
    "        else:\n",
    "            print('The method does not exist')\n",
    "\n",
    "        di=self.DisparateImpact(train_tranf)\n",
    "        print('Disparate Impact of train',di)\n",
    "\n",
    "        if method != 'LFR':\n",
    "            X_train = np.delete(train_tranf.features, self.pa_index, axis=1)\n",
    "            y_train = train_tranf.labels.ravel()\n",
    "            weight_train = train_tranf.instance_weights\n",
    "            model=RandomForestClassifier(max_depth=5).fit(X_train,y_train, sample_weight=weight_train)\n",
    "\n",
    "            X_test = np.delete(test_tranf.features, self.pa_index, axis=1)\n",
    "            y_pred = model.predict(X_test)\n",
    "        else:\n",
    "            y_pred = test_tranf.labels\n",
    "        return y_pred,di\n",
    "    \n",
    "    def DisparateImpact(self,data):\n",
    "        \"\"\"\n",
    "        Computes Disparate Impact of the given dataset.\n",
    "\n",
    "        Parameters:\n",
    "            data (aif360.datasets.BinaryLabelDataset).\n",
    "        \"\"\"\n",
    "        di = pd.DataFrame({'S':data.protected_attributes.ravel().tolist(),\n",
    "            'Y':data.labels.ravel().tolist(),\n",
    "            'W':list(data.instance_weights)},columns=['S','Y','W'])\n",
    "        privileged = self.train.privileged_protected_attributes[0][0]\n",
    "        unprivileged = self.train.unprivileged_protected_attributes[0][0]\n",
    "        numerator=sum(di[(di['S']==unprivileged)&(di['Y']==data.favorable_label)]['W'])/sum(di[di['S']==unprivileged]['W'])\n",
    "        denominator=sum(di[(di['S']==privileged)&(di['Y']==data.favorable_label)]['W'])/sum(di[di['S']==privileged]['W'])\n",
    "        if numerator==denominator:\n",
    "            return 1\n",
    "        return numerator/denominator\n",
    "\n",
    "    def assess(self,method):\n",
    "        \"\"\"\n",
    "        Calculate performance metrics for a given fairness method.\n",
    "\n",
    "        Computes Disparate Impact and three types of F1 scores of the prediction on (processed) test data.\n",
    "\n",
    "        Parameters:\n",
    "            methods (str): The name of the method to evaluate.\n",
    "                        Must be one of ['origin', 'RW', 'DIremover', 'LFR'].\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing the performance metrics\n",
    "                        for the specified method.\n",
    "        \"\"\"\n",
    "        y_pred,di_train = self.prediction(method)\n",
    "        y_test_pred = self.test.copy()\n",
    "        y_test_pred.labels = y_pred\n",
    "\n",
    "        di=self.DisparateImpact(y_test_pred)\n",
    "        f1_macro = f1_score(self.test.labels, y_pred, average='macro',sample_weight=self.test.instance_weights)\n",
    "        f1_micro = f1_score(self.test.labels, y_pred, average='micro',sample_weight=self.test.instance_weights)\n",
    "        f1_weighted = f1_score(self.test.labels, y_pred, average='weighted',sample_weight=self.test.instance_weights)\n",
    "        print('Disparate Impact of '+str(method),di)\n",
    "        print('f1 macro of '+str(method),f1_macro)\n",
    "\n",
    "        new_row=pd.Series({'DI of train':di_train,'DI':di,'f1 macro':f1_macro,'f1 micro':f1_micro,'f1 weighted':f1_weighted,'method':method})\n",
    "        return new_row.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baselinepreprocess:\n",
    "    \"\"\"\n",
    "    A class to evaluate fairness and performance of 3 bias mitigation methods\n",
    "    in the AIF360 documentation:https://aif360.readthedocs.io/en/latest/modules/algorithms.html.\n",
    "\n",
    "    This class supports methods like Reweighing, Disparate Impact Remover, and LFR (Learning fair representations)\n",
    "    to preprocess data, train models, and assess fairness metrics of \n",
    "    Disparate Impact and F1 scores.\n",
    "\n",
    "    Parameters:\n",
    "        train, test (aif360.datasets.BinaryLabelDataset): The dataset to be evaluated.\n",
    "        pa (str): The name of the protected attribute (e.g., 'sex', 'race').\n",
    "   \n",
    "    Methods:\n",
    "        preprocessing(method): Preprocess the dataset using the specified method.\n",
    "        prediction(method): Predict outcomes using a random forest on the test data.\n",
    "        assess(method): Compute performance and fairness metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,train,test):\n",
    "        self.train = train \n",
    "        self.test = test\n",
    "        self.pa = train.protected_attribute_names[0]\n",
    "        self.pa_index = train.feature_names.index(self.pa)\n",
    "        self.prigroups = [{self.pa: 1}]\n",
    "        self.unprigroups = [{self.pa: 0}]\n",
    "\n",
    "    def preprocessing(self,method):\n",
    "        \"\"\"\n",
    "        Preprocess training and/or test data for a given fairness method.\n",
    "\n",
    "        Applies preprocessing steps as described in the AIF360 documentation:\n",
    "        https://aif360.readthedocs.io/en/latest/modules/algorithms.html\n",
    "\n",
    "        Parameters:\n",
    "            methods (str): The name of the method to evaluate.\n",
    "                        Must be one of ['origin', 'RW', 'DIremover', 'LFR'].\n",
    "\n",
    "        Returns:\n",
    "            aif360.datasets.BinaryLabelDataset: The processed training and test data.\n",
    "        \"\"\"\n",
    "        test_tranf = self.test.copy()\n",
    "        if method == 'RW':\n",
    "            RW = Reweighing(privileged_groups = self.prigroups,\n",
    "                            unprivileged_groups = self.unprigroups)\n",
    "            RW.fit(self.train)\n",
    "            train_tranf = RW.transform(self.train)\n",
    "        elif method == 'DIremover':\n",
    "            di = DisparateImpactRemover(repair_level = 1,\n",
    "                                        sensitive_attribute=self.pa)\n",
    "            train_tranf = di.fit_transform(self.train)\n",
    "            test_tranf = di.fit_transform(self.test)\n",
    "        elif method == 'LFR':\n",
    "            TR = LFR(privileged_groups = self.prigroups,\n",
    "                     unprivileged_groups = self.unprigroups,\n",
    "                     Az = 1, Ax = 0.01, Ay = 1,verbose=0)\n",
    "            TR = TR.fit(self.train)\n",
    "            train_tranf = TR.transform(self.train)\n",
    "            test_tranf = TR.transform(self.test)\n",
    "        return train_tranf, test_tranf\n",
    "\n",
    "    def prediction(self,method):\n",
    "        \"\"\"\n",
    "        Predict outcomes using a random forest classifier with a given fairness method.\n",
    "\n",
    "        Parameters:\n",
    "            methods (str): The name of the method to evaluate.\n",
    "                        Must be one of ['origin', 'RW', 'DIremover', 'LFR'].\n",
    "\n",
    "        Returns:\n",
    "            y_pred (aif360.datasets.BinaryLabelDataset): Predictions on the test data.\n",
    "            di (float): Disparate Impact computed on the (processed) training data.\n",
    "        \"\"\"\n",
    "        test_tranf = self.test.copy()\n",
    "        if method == 'origin':\n",
    "            train_tranf = self.train\n",
    "        elif method in ['RW','DIremover','LFR','OP']:\n",
    "            train_tranf,test_tranf = self.preprocessing(method)\n",
    "        else:\n",
    "            print('The method does not exist')\n",
    "\n",
    "        di=self.DisparateImpact(train_tranf)\n",
    "        print('Disparate Impact of train',di)\n",
    "\n",
    "        if method != 'LFR':\n",
    "            X_train = np.delete(train_tranf.features, self.pa_index, axis=1)\n",
    "            y_train = train_tranf.labels.ravel()\n",
    "            weight_train = train_tranf.instance_weights\n",
    "            model=RandomForestClassifier(max_depth=5).fit(X_train,y_train, sample_weight=weight_train)\n",
    "\n",
    "            X_test = np.delete(test_tranf.features, self.pa_index, axis=1)\n",
    "            y_pred = model.predict(X_test)\n",
    "        else:\n",
    "            y_pred = test_tranf.labels\n",
    "        return y_pred,di\n",
    "    \n",
    "    def DisparateImpact(self,data):\n",
    "        \"\"\"\n",
    "        Computes Disparate Impact of the given dataset.\n",
    "\n",
    "        Parameters:\n",
    "            data (aif360.datasets.BinaryLabelDataset).\n",
    "        \"\"\"\n",
    "        di = pd.DataFrame({'S':data.protected_attributes.ravel().tolist(),\n",
    "            'Y':data.labels.ravel().tolist(),\n",
    "            'W':list(data.instance_weights)},columns=['S','Y','W'])\n",
    "        privileged = self.train.privileged_protected_attributes[0][0]\n",
    "        unprivileged = self.train.unprivileged_protected_attributes[0][0]\n",
    "        numerator=sum(di[(di['S']==unprivileged)&(di['Y']==data.favorable_label)]['W'])/sum(di[di['S']==unprivileged]['W'])\n",
    "        denominator=sum(di[(di['S']==privileged)&(di['Y']==data.favorable_label)]['W'])/sum(di[di['S']==privileged]['W'])\n",
    "        if numerator==denominator:\n",
    "            return 1\n",
    "        return numerator/denominator\n",
    "\n",
    "    def assess(self,method):\n",
    "        \"\"\"\n",
    "        Calculate performance metrics for a given fairness method.\n",
    "\n",
    "        Computes Disparate Impact and three types of F1 scores of the prediction on (processed) test data.\n",
    "\n",
    "        Parameters:\n",
    "            methods (str): The name of the method to evaluate.\n",
    "                        Must be one of ['origin', 'RW', 'DIremover', 'LFR'].\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing the performance metrics\n",
    "                        for the specified method.\n",
    "        \"\"\"\n",
    "        y_pred,di_train = self.prediction(method)\n",
    "        y_test_pred = self.test.copy()\n",
    "        y_test_pred.labels = y_pred\n",
    "\n",
    "        di=self.DisparateImpact(y_test_pred)\n",
    "        f1_macro = f1_score(self.test.labels, y_pred, average='macro',sample_weight=self.test.instance_weights)\n",
    "        f1_micro = f1_score(self.test.labels, y_pred, average='micro',sample_weight=self.test.instance_weights)\n",
    "        f1_weighted = f1_score(self.test.labels, y_pred, average='weighted',sample_weight=self.test.instance_weights)\n",
    "        print('Disparate Impact of '+str(method),di)\n",
    "        print('f1 macro of '+str(method),f1_macro)\n",
    "\n",
    "        new_row=pd.Series({'DI of train':di_train,'DI':di,'f1 macro':f1_macro,'f1 micro':f1_micro,'f1 weighted':f1_weighted,'method':method})\n",
    "        return new_row.to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compas dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = 'race'\n",
    "label_map = {1.0: 'Did recid.', 0.0: 'No recid.'}\n",
    "protected_attribute_maps = {1.0: 'Caucasian', 0.0: 'Not Caucasian'}\n",
    "privileged_groups = [{pa: 1}]\n",
    "unprivileged_groups = [{pa: 0}]\n",
    "cd = CompasDataset(protected_attribute_names=[pa],privileged_classes=[['Caucasian'],[1]], \n",
    "                    metadata={'label_map': label_map,'protected_attribute_maps': protected_attribute_maps},\n",
    "                    features_to_drop=['age', 'sex', 'c_charge_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.7990349420367482\n",
      "Disparate Impact of origin 0.7932470145168625\n",
      "f1 macro of origin 0.6777809337135148\n",
      "Disparate Impact of train 0.999999999999987\n",
      "Disparate Impact of RW 0.8262149542418952\n",
      "f1 macro of RW 0.6690655415745095\n",
      "Disparate Impact of train 0.7990349420367482\n",
      "Disparate Impact of DIremover 0.7704704850964349\n",
      "f1 macro of DIremover 0.6831997426375959\n",
      "Disparate Impact of train 1.0001618880631213\n",
      "Disparate Impact of LFR 1.0072635885447108\n",
      "f1 macro of LFR 0.6803522689911459\n",
      "Disparate Impact of train 0.7959084008243232\n",
      "Disparate Impact of origin 0.7410729687769535\n",
      "f1 macro of origin 0.6523691094564642\n",
      "Disparate Impact of train 1.0000000000000004\n",
      "Disparate Impact of RW 0.7439167441527788\n",
      "f1 macro of RW 0.6460775469961576\n",
      "Disparate Impact of train 0.7959084008243232\n",
      "Disparate Impact of DIremover 0.8364702745934417\n",
      "f1 macro of DIremover 0.6520259007179265\n",
      "Disparate Impact of train 0.9043388068572494\n",
      "Disparate Impact of LFR 0.8756245693316027\n",
      "f1 macro of LFR 0.6501686421894575\n",
      "Disparate Impact of train 0.8537031822021967\n",
      "Disparate Impact of origin 0.7926476489256922\n",
      "f1 macro of origin 0.6646429161086753\n",
      "Disparate Impact of train 1.0000000000000138\n",
      "Disparate Impact of RW 0.7967339097022095\n",
      "f1 macro of RW 0.6646429161086753\n",
      "Disparate Impact of train 0.8537031822021967\n",
      "Disparate Impact of DIremover 0.9245093537830313\n",
      "f1 macro of DIremover 0.6480428511806051\n",
      "Disparate Impact of train 0.9442861307827592\n",
      "Disparate Impact of LFR 0.9792174904463707\n",
      "f1 macro of LFR 0.6643965826536926\n",
      "Disparate Impact of train 0.8094011064581266\n",
      "Disparate Impact of origin 0.8245496948529139\n",
      "f1 macro of origin 0.6678161178152224\n",
      "Disparate Impact of train 0.9999999999999584\n",
      "Disparate Impact of RW 0.8262257451310929\n",
      "f1 macro of RW 0.6635591161563179\n",
      "Disparate Impact of train 0.8094011064581266\n",
      "Disparate Impact of DIremover 0.9166603899907942\n",
      "f1 macro of DIremover 0.6747874231578794\n",
      "Disparate Impact of train 1.009942366646229\n",
      "Disparate Impact of LFR 1.1244116821809995\n",
      "f1 macro of LFR 0.6590879901338282\n",
      "Disparate Impact of train 0.8383767954260215\n",
      "Disparate Impact of origin 0.7968879384786699\n",
      "f1 macro of origin 0.6587094593915322\n",
      "Disparate Impact of train 1.000000000000006\n",
      "Disparate Impact of RW 0.7984454017606292\n",
      "f1 macro of RW 0.6575324056030841\n",
      "Disparate Impact of train 0.8383767954260215\n",
      "Disparate Impact of DIremover 0.7502616082019997\n",
      "f1 macro of DIremover 0.648731565291971\n",
      "Disparate Impact of train 0.9439087284669306\n",
      "Disparate Impact of LFR 0.9611546065638592\n",
      "f1 macro of LFR 0.6619320445310406\n",
      "Disparate Impact of train 0.8292452099091884\n",
      "Disparate Impact of origin 0.8223711468346039\n",
      "f1 macro of origin 0.6568459024628941\n",
      "Disparate Impact of train 1.0000000000000233\n",
      "Disparate Impact of RW 0.8136146129785621\n",
      "f1 macro of RW 0.6593582312620905\n",
      "Disparate Impact of train 0.8292452099091884\n",
      "Disparate Impact of DIremover 0.8094399376767659\n",
      "f1 macro of DIremover 0.6634895457822639\n",
      "Disparate Impact of train 0.9717607353723867\n",
      "Disparate Impact of LFR 1.077005249357042\n",
      "f1 macro of LFR 0.6583243381792845\n",
      "Disparate Impact of train 0.8366963572137405\n",
      "Disparate Impact of origin 0.7122551678038568\n",
      "f1 macro of origin 0.6524675566847506\n",
      "Disparate Impact of train 1.000000000000022\n",
      "Disparate Impact of RW 0.7581342307799466\n",
      "f1 macro of RW 0.661718293661346\n",
      "Disparate Impact of train 0.8366963572137405\n",
      "Disparate Impact of DIremover 0.7071488792901894\n",
      "f1 macro of DIremover 0.6521026577737055\n",
      "Disparate Impact of train 0.9655036113406877\n",
      "Disparate Impact of LFR 1.017073555899875\n",
      "f1 macro of LFR 0.6601345898286983\n",
      "Disparate Impact of train 0.8461478715459297\n",
      "Disparate Impact of origin 0.7461241809833359\n",
      "f1 macro of origin 0.6675552147462929\n",
      "Disparate Impact of train 1.0000000000000049\n",
      "Disparate Impact of RW 0.7462591549295774\n",
      "f1 macro of RW 0.6682151378580007\n",
      "Disparate Impact of train 0.8461478715459297\n",
      "Disparate Impact of DIremover 0.8552831214931867\n",
      "f1 macro of DIremover 0.6699232671150508\n",
      "Disparate Impact of train 0.951076923076923\n",
      "Disparate Impact of LFR 0.9235246272959393\n",
      "f1 macro of LFR 0.664351308689545\n",
      "Disparate Impact of train 0.8177415382931568\n",
      "Disparate Impact of origin 0.7478431240645128\n",
      "f1 macro of origin 0.6670120668659361\n",
      "Disparate Impact of train 1.0000000000000233\n",
      "Disparate Impact of RW 0.7472873734509206\n",
      "f1 macro of RW 0.6641144965191353\n",
      "Disparate Impact of train 0.8177415382931568\n",
      "Disparate Impact of DIremover 0.846797728477813\n",
      "f1 macro of DIremover 0.6600578457516827\n",
      "Disparate Impact of train 0.9839610445456768\n",
      "Disparate Impact of LFR 0.959694672421376\n",
      "f1 macro of LFR 0.6664156680700997\n",
      "Disparate Impact of train 0.8581902735863058\n",
      "Disparate Impact of origin 0.7876810573750703\n",
      "f1 macro of origin 0.680703769266652\n",
      "Disparate Impact of train 0.9999999999999735\n",
      "Disparate Impact of RW 0.7868029291059789\n",
      "f1 macro of RW 0.6803416201487769\n",
      "Disparate Impact of train 0.8581902735863058\n",
      "Disparate Impact of DIremover 0.8791290039491007\n",
      "f1 macro of DIremover 0.6833909555911635\n",
      "Disparate Impact of train 0.969122049369387\n",
      "Disparate Impact of LFR 0.9954755363993747\n",
      "f1 macro of LFR 0.6785530742057975\n"
     ]
    }
   ],
   "source": [
    "methods=['origin','RW','DIremover','LFR'] \n",
    "report=pd.DataFrame(columns=['DI of train','DI','f1 macro','f1 micro','f1 weighted','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    train,test = cd.split([0.4], shuffle=True) \n",
    "    valid,test = test.split([0.3], shuffle=True)\n",
    "    \n",
    "    prepro = Baselinepreprocess(train,test)\n",
    "    for method in methods:\n",
    "        report = pd.concat([report,prepro.assess(method)], ignore_index=True)\n",
    "\n",
    "report.to_csv(path+'/data/report_preprocess_compas_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path,var_list,pa):\n",
    "    \"\"\"\n",
    "    Load and clean the Adult dataset, and discretize selected attributes \n",
    "    (age, hours-per-week, capital-gain, capital-loss).\n",
    "\n",
    "    Parameters:\n",
    "        data_path (str): Path to the input data file.\n",
    "        var_list (list of str): List of non-protected attribute names.\n",
    "        pa (str): Name of the protected attribute.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned dataset with discretized attributes.\n",
    "    \"\"\"\n",
    "\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education',\n",
    "                'education-num', 'marital-status', 'occupation', 'relationship',\n",
    "                'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                'native-country', 'Y']\n",
    "    na_values=['?']\n",
    "    pa_dict={'Male':1,'Female':0,'White':1,'Black':0}\n",
    "    label_dict={'>50K.':1,'>50K':1,'<=50K.':0,'<=50K':0}\n",
    "    train_path = os.path.join(data_path, 'adult.data')\n",
    "    test_path = os.path.join(data_path, 'adult.test')\n",
    "    train = pd.read_csv(train_path, header=None,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    test = pd.read_csv(test_path, header=0,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    messydata = pd.concat([test, train], ignore_index=True)[var_list+[pa,'Y']]\n",
    "    messydata=messydata.rename(columns={pa:'S'})\n",
    "    messydata['S']=messydata['S'].replace(pa_dict)\n",
    "    messydata['Y']=messydata['Y'].replace(label_dict)\n",
    "    messydata=messydata[(messydata['S']==0)|(messydata['S']==1)]\n",
    "    for col in var_list+['S','Y']:\n",
    "        messydata[col]=messydata[col].astype('int64')\n",
    "    messydata['W']=1\n",
    "\n",
    "    # Define bin thresholds for discretizing attributes.\n",
    "    bins_capitalgain=[100,3500,7500,10000]\n",
    "    bins_capitalloss=[100,1600,1900,2200]\n",
    "    bins_age=[26,36,46,56]\n",
    "    bins_hours=[21,36,46,61]\n",
    "\n",
    "    # Apply discretization to attributes using predefined bins.\n",
    "    messydata=categerise(messydata,'age',bins_age)\n",
    "    messydata=categerise(messydata,'hours-per-week',bins_hours)\n",
    "    messydata=categerise(messydata,'capital-gain',bins_capitalgain)\n",
    "    messydata=categerise(messydata,'capital-loss',bins_capitalloss)\n",
    "    \n",
    "    return messydata\n",
    "\n",
    "def categerise(df,col,bins):\n",
    "    # Apply discretization to attributes using predefined bins.\n",
    "    for i in range(len(bins)+1):\n",
    "        if i == 0:\n",
    "            df.loc[df[col] < bins[i], col] = i\n",
    "        elif i == len(bins):\n",
    "            df.loc[df[col] >= bins[i-1], col] = i\n",
    "        else:\n",
    "            df.loc[(df[col] >= bins[i-1])& (df[col] < bins[i]), col] = i        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_x(var_list,messydata):\n",
    "    \"\"\"\n",
    "    Select non-protected attributes to repair based on their \n",
    "    protected-attribute-wise Total Variation distance.\n",
    "\n",
    "    Attributes are selected if their Total Variation distance exceeds a threshold (default: 0.1).\n",
    "\n",
    "    Parameters:\n",
    "        var_list (list of str): List of non-protected attribute names.\n",
    "        messydata (pd.DataFrame): The cleaned dataset.\n",
    "\n",
    "    Returns:\n",
    "        x_list (list of str): List of non-protected attributes that need to be repaired.\n",
    "        tv_dist (dict): Dictionary mapping each non-protected attribute to its \n",
    "                        protected-attribute-wise Total Variation distance.\n",
    "    \"\"\"\n",
    "\n",
    "    tv_dist=dict()\n",
    "    for x_name in var_list:\n",
    "        x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index) \n",
    "        dist=rdata_analysis(messydata,x_range_single,x_name)\n",
    "        tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "    x_list=[]\n",
    "    for key,val in tv_dist.items():\n",
    "        if val>0.1:\n",
    "            x_list+=[key]  \n",
    "    return x_list,tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='C://Users//zhouq//anaconda3//Lib//site-packages//aif360//data//raw//adult'\n",
    "var_list=['hours-per-week','age','capital-gain','capital-loss','education-num'] #,'education-num'\n",
    "pa='race'\n",
    "favorable_label = 1\n",
    "var_dim=len(var_list)\n",
    "\n",
    "messydata = load_data(data_path,var_list,pa)\n",
    "x_list,tv_dist = choose_x(var_list,messydata)\n",
    "messydata=messydata.rename(columns={'S':pa})\n",
    "cd=BinaryLabelDataset(\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0,\n",
    "    df=messydata,label_names='Y',protected_attribute_names=[pa])\n",
    "# train,test = cd.split([0.4], shuffle=True) \n",
    "# valid,test = test.split([0.3], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.4423024479779176\n",
      "Disparate Impact of origin 0.4761241484554046\n",
      "f1 macro of origin 0.6696624107858051\n",
      "Disparate Impact of train 0.9999999999998899\n",
      "Disparate Impact of RW 0.46521121614598077\n",
      "f1 macro of RW 0.6779482632516027\n",
      "Disparate Impact of train 0.4423024479779176\n",
      "Disparate Impact of DIremover 0.4754678848427709\n",
      "f1 macro of DIremover 0.6761039218256115\n",
      "Disparate Impact of train 0.8188911000561955\n",
      "Disparate Impact of LFR 0.8403672932237478\n",
      "f1 macro of LFR 0.6921478761007314\n",
      "Disparate Impact of train 0.45067826635145786\n",
      "Disparate Impact of origin 0.49080822521331785\n",
      "f1 macro of origin 0.6820805989657579\n",
      "Disparate Impact of train 1.0000000000003044\n",
      "Disparate Impact of RW 0.48527679623085984\n",
      "f1 macro of RW 0.6765581603975014\n",
      "Disparate Impact of train 0.45067826635145786\n",
      "Disparate Impact of DIremover 0.4790061250933923\n",
      "f1 macro of DIremover 0.6799367478843286\n",
      "Disparate Impact of train 0.7768607938615907\n",
      "Disparate Impact of LFR 0.7838645991916943\n",
      "f1 macro of LFR 0.6852461845853519\n",
      "Disparate Impact of train 0.4619546191214598\n",
      "Disparate Impact of origin 0.45637323184961964\n",
      "f1 macro of origin 0.6749153401155569\n",
      "Disparate Impact of train 0.999999999999862\n",
      "Disparate Impact of RW 0.4645428150976415\n",
      "f1 macro of RW 0.67427439322347\n",
      "Disparate Impact of train 0.4619546191214598\n",
      "Disparate Impact of DIremover 0.4744699337628779\n",
      "f1 macro of DIremover 0.6760720119892479\n",
      "Disparate Impact of train 0.7925409089084856\n",
      "Disparate Impact of LFR 0.7940217108163985\n",
      "f1 macro of LFR 0.6889898624647122\n",
      "Disparate Impact of train 0.4896358346382201\n",
      "Disparate Impact of origin 0.3867278866764607\n",
      "f1 macro of origin 0.6812181376260478\n",
      "Disparate Impact of train 1.0000000000001594\n",
      "Disparate Impact of RW 0.3946254212922438\n",
      "f1 macro of RW 0.6609939589700606\n",
      "Disparate Impact of train 0.4896358346382201\n",
      "Disparate Impact of DIremover 0.3703514200926873\n",
      "f1 macro of DIremover 0.6736112419193034\n",
      "Disparate Impact of train 0.8166565986367389\n",
      "Disparate Impact of LFR 0.7976567418146462\n",
      "f1 macro of LFR 0.6945838879009869\n",
      "Disparate Impact of train 0.514807684214956\n",
      "Disparate Impact of origin 0.42534165413511005\n",
      "f1 macro of origin 0.679942723053309\n",
      "Disparate Impact of train 0.9999999999997609\n",
      "Disparate Impact of RW 0.43376412814795473\n",
      "f1 macro of RW 0.6808140780641915\n",
      "Disparate Impact of train 0.514807684214956\n",
      "Disparate Impact of DIremover 0.43034823450619886\n",
      "f1 macro of DIremover 0.6797014306799523\n",
      "Disparate Impact of train 0.8750772481262185\n",
      "Disparate Impact of LFR 0.8120135018199436\n",
      "f1 macro of LFR 0.6964399440357925\n",
      "Disparate Impact of train 0.46519164517648554\n",
      "Disparate Impact of origin 0.5087143047475241\n",
      "f1 macro of origin 0.6813857495114106\n",
      "Disparate Impact of train 0.9999999999999366\n",
      "Disparate Impact of RW 0.5216105343124842\n",
      "f1 macro of RW 0.6888684604410261\n",
      "Disparate Impact of train 0.46519164517648554\n",
      "Disparate Impact of DIremover 0.5077117744469449\n",
      "f1 macro of DIremover 0.6883610276168922\n",
      "Disparate Impact of train 0.8008620689655173\n",
      "Disparate Impact of LFR 0.9110297514393078\n",
      "f1 macro of LFR 0.696705989443378\n",
      "Disparate Impact of train 0.45173184380302833\n",
      "Disparate Impact of origin 0.5224055777822585\n",
      "f1 macro of origin 0.6820145663333177\n",
      "Disparate Impact of train 1.0000000000001483\n",
      "Disparate Impact of RW 0.5091016207993702\n",
      "f1 macro of RW 0.689224309608689\n",
      "Disparate Impact of train 0.45173184380302833\n",
      "Disparate Impact of DIremover 0.5105015802585955\n",
      "f1 macro of DIremover 0.6811543048985529\n",
      "Disparate Impact of train 0.7309188810569225\n",
      "Disparate Impact of LFR 0.8507213216443911\n",
      "f1 macro of LFR 0.6978326509408188\n",
      "Disparate Impact of train 0.47968053176107783\n",
      "Disparate Impact of origin 0.41728772434546096\n",
      "f1 macro of origin 0.6759675778329068\n",
      "Disparate Impact of train 1.000000000000237\n",
      "Disparate Impact of RW 0.40926739092722697\n",
      "f1 macro of RW 0.6706892818235476\n",
      "Disparate Impact of train 0.47968053176107783\n",
      "Disparate Impact of DIremover 0.4065249606372141\n",
      "f1 macro of DIremover 0.6726831996052693\n",
      "Disparate Impact of train 0.9357545473220625\n",
      "Disparate Impact of LFR 0.8834083906843397\n",
      "f1 macro of LFR 0.6862595325893764\n",
      "Disparate Impact of train 0.45553290296844845\n",
      "Disparate Impact of origin 0.5076748142507296\n",
      "f1 macro of origin 0.6867406474491867\n",
      "Disparate Impact of train 1.0000000000001756\n",
      "Disparate Impact of RW 0.5280251454891369\n",
      "f1 macro of RW 0.6644919853251716\n",
      "Disparate Impact of train 0.45553290296844845\n",
      "Disparate Impact of DIremover 0.5119918781476149\n",
      "f1 macro of DIremover 0.682850353667898\n",
      "Disparate Impact of train 0.7145153256604923\n",
      "Disparate Impact of LFR 0.7375479655596388\n",
      "f1 macro of LFR 0.6954052688016314\n",
      "Disparate Impact of train 0.4579237489947454\n",
      "Disparate Impact of origin 0.6098994252873563\n",
      "f1 macro of origin 0.6787992297553438\n",
      "Disparate Impact of train 0.9999999999999943\n",
      "Disparate Impact of RW 0.6019130494247176\n",
      "f1 macro of RW 0.6853698684940933\n",
      "Disparate Impact of train 0.4579237489947454\n",
      "Disparate Impact of DIremover 0.6288973665691321\n",
      "f1 macro of DIremover 0.6755356785218325\n",
      "Disparate Impact of train 0.7569330629685916\n",
      "Disparate Impact of LFR 0.9359070464767616\n",
      "f1 macro of LFR 0.6901917069488299\n"
     ]
    }
   ],
   "source": [
    "methods=['origin','RW','DIremover','LFR'] \n",
    "report=pd.DataFrame(columns=['DI of train','DI','f1 macro','f1 micro','f1 weighted','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    train,test = cd.split([0.4], shuffle=True) \n",
    "    valid,test = test.split([0.3], shuffle=True)\n",
    "    \n",
    "    prepro = Baselinepreprocess(train,test)\n",
    "    for method in methods:\n",
    "        report = pd.concat([report,prepro.assess(method)], ignore_index=True)\n",
    "\n",
    "report.to_csv(path+'/data/report_preprocess_adult_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI of train</th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.442302</td>\n",
       "      <td>0.476124</td>\n",
       "      <td>0.669662</td>\n",
       "      <td>0.812599</td>\n",
       "      <td>0.782036</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.465211</td>\n",
       "      <td>0.677948</td>\n",
       "      <td>0.814598</td>\n",
       "      <td>0.786436</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.442302</td>\n",
       "      <td>0.475468</td>\n",
       "      <td>0.676104</td>\n",
       "      <td>0.814035</td>\n",
       "      <td>0.785411</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.818891</td>\n",
       "      <td>0.840367</td>\n",
       "      <td>0.692148</td>\n",
       "      <td>0.808294</td>\n",
       "      <td>0.789936</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.450678</td>\n",
       "      <td>0.490808</td>\n",
       "      <td>0.682081</td>\n",
       "      <td>0.816341</td>\n",
       "      <td>0.787928</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.485277</td>\n",
       "      <td>0.676558</td>\n",
       "      <td>0.815162</td>\n",
       "      <td>0.785034</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.450678</td>\n",
       "      <td>0.479006</td>\n",
       "      <td>0.679937</td>\n",
       "      <td>0.815316</td>\n",
       "      <td>0.786582</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.776861</td>\n",
       "      <td>0.783865</td>\n",
       "      <td>0.685246</td>\n",
       "      <td>0.807268</td>\n",
       "      <td>0.785651</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.461955</td>\n",
       "      <td>0.456373</td>\n",
       "      <td>0.674915</td>\n",
       "      <td>0.810088</td>\n",
       "      <td>0.780571</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464543</td>\n",
       "      <td>0.674274</td>\n",
       "      <td>0.810036</td>\n",
       "      <td>0.780265</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.461955</td>\n",
       "      <td>0.47447</td>\n",
       "      <td>0.676072</td>\n",
       "      <td>0.810293</td>\n",
       "      <td>0.781168</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.792541</td>\n",
       "      <td>0.794022</td>\n",
       "      <td>0.68899</td>\n",
       "      <td>0.808294</td>\n",
       "      <td>0.786078</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.489636</td>\n",
       "      <td>0.386728</td>\n",
       "      <td>0.681218</td>\n",
       "      <td>0.815419</td>\n",
       "      <td>0.787482</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.394625</td>\n",
       "      <td>0.660994</td>\n",
       "      <td>0.811779</td>\n",
       "      <td>0.777151</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.489636</td>\n",
       "      <td>0.370351</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.813522</td>\n",
       "      <td>0.783399</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.816657</td>\n",
       "      <td>0.797657</td>\n",
       "      <td>0.694584</td>\n",
       "      <td>0.807781</td>\n",
       "      <td>0.790111</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.514808</td>\n",
       "      <td>0.425342</td>\n",
       "      <td>0.679943</td>\n",
       "      <td>0.817828</td>\n",
       "      <td>0.790283</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.433764</td>\n",
       "      <td>0.680814</td>\n",
       "      <td>0.818238</td>\n",
       "      <td>0.79082</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.514808</td>\n",
       "      <td>0.430348</td>\n",
       "      <td>0.679701</td>\n",
       "      <td>0.818186</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.875077</td>\n",
       "      <td>0.812014</td>\n",
       "      <td>0.69644</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.795396</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.465192</td>\n",
       "      <td>0.508714</td>\n",
       "      <td>0.681386</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.78851</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.521611</td>\n",
       "      <td>0.688868</td>\n",
       "      <td>0.817315</td>\n",
       "      <td>0.792517</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.465192</td>\n",
       "      <td>0.507712</td>\n",
       "      <td>0.688361</td>\n",
       "      <td>0.817366</td>\n",
       "      <td>0.79232</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.800862</td>\n",
       "      <td>0.91103</td>\n",
       "      <td>0.696706</td>\n",
       "      <td>0.80978</td>\n",
       "      <td>0.792722</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.451732</td>\n",
       "      <td>0.522406</td>\n",
       "      <td>0.682015</td>\n",
       "      <td>0.818238</td>\n",
       "      <td>0.790436</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.509102</td>\n",
       "      <td>0.689224</td>\n",
       "      <td>0.820903</td>\n",
       "      <td>0.794607</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.451732</td>\n",
       "      <td>0.510502</td>\n",
       "      <td>0.681154</td>\n",
       "      <td>0.817981</td>\n",
       "      <td>0.789963</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.730919</td>\n",
       "      <td>0.850721</td>\n",
       "      <td>0.697833</td>\n",
       "      <td>0.8106</td>\n",
       "      <td>0.793995</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.479681</td>\n",
       "      <td>0.417288</td>\n",
       "      <td>0.675968</td>\n",
       "      <td>0.812702</td>\n",
       "      <td>0.783721</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409267</td>\n",
       "      <td>0.670689</td>\n",
       "      <td>0.81183</td>\n",
       "      <td>0.781054</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.479681</td>\n",
       "      <td>0.406525</td>\n",
       "      <td>0.672683</td>\n",
       "      <td>0.811677</td>\n",
       "      <td>0.781873</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.935755</td>\n",
       "      <td>0.883408</td>\n",
       "      <td>0.68626</td>\n",
       "      <td>0.80691</td>\n",
       "      <td>0.785857</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.455533</td>\n",
       "      <td>0.507675</td>\n",
       "      <td>0.686741</td>\n",
       "      <td>0.819263</td>\n",
       "      <td>0.793049</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.528025</td>\n",
       "      <td>0.664492</td>\n",
       "      <td>0.81547</td>\n",
       "      <td>0.781922</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.455533</td>\n",
       "      <td>0.511992</td>\n",
       "      <td>0.68285</td>\n",
       "      <td>0.818545</td>\n",
       "      <td>0.791089</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.714515</td>\n",
       "      <td>0.737548</td>\n",
       "      <td>0.695405</td>\n",
       "      <td>0.816187</td>\n",
       "      <td>0.795482</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.457924</td>\n",
       "      <td>0.609899</td>\n",
       "      <td>0.678799</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.786639</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.601913</td>\n",
       "      <td>0.68537</td>\n",
       "      <td>0.817008</td>\n",
       "      <td>0.790156</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.457924</td>\n",
       "      <td>0.628897</td>\n",
       "      <td>0.675536</td>\n",
       "      <td>0.814752</td>\n",
       "      <td>0.784968</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.756933</td>\n",
       "      <td>0.935907</td>\n",
       "      <td>0.690192</td>\n",
       "      <td>0.808857</td>\n",
       "      <td>0.788916</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DI of train        DI  f1 macro  f1 micro f1 weighted     method\n",
       "0     0.442302  0.476124  0.669662  0.812599    0.782036     origin\n",
       "1          1.0  0.465211  0.677948  0.814598    0.786436         RW\n",
       "2     0.442302  0.475468  0.676104  0.814035    0.785411  DIremover\n",
       "3     0.818891  0.840367  0.692148  0.808294    0.789936        LFR\n",
       "4     0.450678  0.490808  0.682081  0.816341    0.787928     origin\n",
       "5          1.0  0.485277  0.676558  0.815162    0.785034         RW\n",
       "6     0.450678  0.479006  0.679937  0.815316    0.786582  DIremover\n",
       "7     0.776861  0.783865  0.685246  0.807268    0.785651        LFR\n",
       "8     0.461955  0.456373  0.674915  0.810088    0.780571     origin\n",
       "9          1.0  0.464543  0.674274  0.810036    0.780265         RW\n",
       "10    0.461955   0.47447  0.676072  0.810293    0.781168  DIremover\n",
       "11    0.792541  0.794022   0.68899  0.808294    0.786078        LFR\n",
       "12    0.489636  0.386728  0.681218  0.815419    0.787482     origin\n",
       "13         1.0  0.394625  0.660994  0.811779    0.777151         RW\n",
       "14    0.489636  0.370351  0.673611  0.813522    0.783399  DIremover\n",
       "15    0.816657  0.797657  0.694584  0.807781    0.790111        LFR\n",
       "16    0.514808  0.425342  0.679943  0.817828    0.790283     origin\n",
       "17         1.0  0.433764  0.680814  0.818238     0.79082         RW\n",
       "18    0.514808  0.430348  0.679701  0.818186    0.790323  DIremover\n",
       "19    0.875077  0.812014   0.69644  0.813368    0.795396        LFR\n",
       "20    0.465192  0.508714  0.681386  0.815367     0.78851     origin\n",
       "21         1.0  0.521611  0.688868  0.817315    0.792517         RW\n",
       "22    0.465192  0.507712  0.688361  0.817366     0.79232  DIremover\n",
       "23    0.800862   0.91103  0.696706   0.80978    0.792722        LFR\n",
       "24    0.451732  0.522406  0.682015  0.818238    0.790436     origin\n",
       "25         1.0  0.509102  0.689224  0.820903    0.794607         RW\n",
       "26    0.451732  0.510502  0.681154  0.817981    0.789963  DIremover\n",
       "27    0.730919  0.850721  0.697833    0.8106    0.793995        LFR\n",
       "28    0.479681  0.417288  0.675968  0.812702    0.783721     origin\n",
       "29         1.0  0.409267  0.670689   0.81183    0.781054         RW\n",
       "30    0.479681  0.406525  0.672683  0.811677    0.781873  DIremover\n",
       "31    0.935755  0.883408   0.68626   0.80691    0.785857        LFR\n",
       "32    0.455533  0.507675  0.686741  0.819263    0.793049     origin\n",
       "33         1.0  0.528025  0.664492   0.81547    0.781922         RW\n",
       "34    0.455533  0.511992   0.68285  0.818545    0.791089  DIremover\n",
       "35    0.714515  0.737548  0.695405  0.816187    0.795482        LFR\n",
       "36    0.457924  0.609899  0.678799  0.815367    0.786639     origin\n",
       "37         1.0  0.601913   0.68537  0.817008    0.790156         RW\n",
       "38    0.457924  0.628897  0.675536  0.814752    0.784968  DIremover\n",
       "39    0.756933  0.935907  0.690192  0.808857    0.788916        LFR"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compas dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = 'race'\n",
    "label_map = {1.0: 'Did recid.', 0.0: 'No recid.'}\n",
    "protected_attribute_maps = {1.0: 'Caucasian', 0.0: 'Not Caucasian'}\n",
    "privileged_groups = [{pa: 1}]\n",
    "unprivileged_groups = [{pa: 0}]\n",
    "cd = CompasDataset(protected_attribute_names=[pa],privileged_classes=[['Caucasian'],[1]], \n",
    "                    metadata={'label_map': label_map,'protected_attribute_maps': protected_attribute_maps},\n",
    "                    features_to_drop=['age', 'sex', 'c_charge_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.7990349420367482\n",
      "Disparate Impact of origin 0.7932470145168625\n",
      "f1 macro of origin 0.6777809337135148\n",
      "Disparate Impact of train 0.999999999999987\n",
      "Disparate Impact of RW 0.8262149542418952\n",
      "f1 macro of RW 0.6690655415745095\n",
      "Disparate Impact of train 0.7990349420367482\n",
      "Disparate Impact of DIremover 0.7704704850964349\n",
      "f1 macro of DIremover 0.6831997426375959\n",
      "Disparate Impact of train 1.0001618880631213\n",
      "Disparate Impact of LFR 1.0072635885447108\n",
      "f1 macro of LFR 0.6803522689911459\n",
      "Disparate Impact of train 0.7959084008243232\n",
      "Disparate Impact of origin 0.7410729687769535\n",
      "f1 macro of origin 0.6523691094564642\n",
      "Disparate Impact of train 1.0000000000000004\n",
      "Disparate Impact of RW 0.7439167441527788\n",
      "f1 macro of RW 0.6460775469961576\n",
      "Disparate Impact of train 0.7959084008243232\n",
      "Disparate Impact of DIremover 0.8364702745934417\n",
      "f1 macro of DIremover 0.6520259007179265\n",
      "Disparate Impact of train 0.9043388068572494\n",
      "Disparate Impact of LFR 0.8756245693316027\n",
      "f1 macro of LFR 0.6501686421894575\n",
      "Disparate Impact of train 0.8537031822021967\n",
      "Disparate Impact of origin 0.7926476489256922\n",
      "f1 macro of origin 0.6646429161086753\n",
      "Disparate Impact of train 1.0000000000000138\n",
      "Disparate Impact of RW 0.7967339097022095\n",
      "f1 macro of RW 0.6646429161086753\n",
      "Disparate Impact of train 0.8537031822021967\n",
      "Disparate Impact of DIremover 0.9245093537830313\n",
      "f1 macro of DIremover 0.6480428511806051\n",
      "Disparate Impact of train 0.9442861307827592\n",
      "Disparate Impact of LFR 0.9792174904463707\n",
      "f1 macro of LFR 0.6643965826536926\n",
      "Disparate Impact of train 0.8094011064581266\n",
      "Disparate Impact of origin 0.8245496948529139\n",
      "f1 macro of origin 0.6678161178152224\n",
      "Disparate Impact of train 0.9999999999999584\n",
      "Disparate Impact of RW 0.8262257451310929\n",
      "f1 macro of RW 0.6635591161563179\n",
      "Disparate Impact of train 0.8094011064581266\n",
      "Disparate Impact of DIremover 0.9166603899907942\n",
      "f1 macro of DIremover 0.6747874231578794\n",
      "Disparate Impact of train 1.009942366646229\n",
      "Disparate Impact of LFR 1.1244116821809995\n",
      "f1 macro of LFR 0.6590879901338282\n",
      "Disparate Impact of train 0.8383767954260215\n",
      "Disparate Impact of origin 0.7968879384786699\n",
      "f1 macro of origin 0.6587094593915322\n",
      "Disparate Impact of train 1.000000000000006\n",
      "Disparate Impact of RW 0.7984454017606292\n",
      "f1 macro of RW 0.6575324056030841\n",
      "Disparate Impact of train 0.8383767954260215\n",
      "Disparate Impact of DIremover 0.7502616082019997\n",
      "f1 macro of DIremover 0.648731565291971\n",
      "Disparate Impact of train 0.9439087284669306\n",
      "Disparate Impact of LFR 0.9611546065638592\n",
      "f1 macro of LFR 0.6619320445310406\n",
      "Disparate Impact of train 0.8292452099091884\n",
      "Disparate Impact of origin 0.8223711468346039\n",
      "f1 macro of origin 0.6568459024628941\n",
      "Disparate Impact of train 1.0000000000000233\n",
      "Disparate Impact of RW 0.8136146129785621\n",
      "f1 macro of RW 0.6593582312620905\n",
      "Disparate Impact of train 0.8292452099091884\n",
      "Disparate Impact of DIremover 0.8094399376767659\n",
      "f1 macro of DIremover 0.6634895457822639\n",
      "Disparate Impact of train 0.9717607353723867\n",
      "Disparate Impact of LFR 1.077005249357042\n",
      "f1 macro of LFR 0.6583243381792845\n",
      "Disparate Impact of train 0.8366963572137405\n",
      "Disparate Impact of origin 0.7122551678038568\n",
      "f1 macro of origin 0.6524675566847506\n",
      "Disparate Impact of train 1.000000000000022\n",
      "Disparate Impact of RW 0.7581342307799466\n",
      "f1 macro of RW 0.661718293661346\n",
      "Disparate Impact of train 0.8366963572137405\n",
      "Disparate Impact of DIremover 0.7071488792901894\n",
      "f1 macro of DIremover 0.6521026577737055\n",
      "Disparate Impact of train 0.9655036113406877\n",
      "Disparate Impact of LFR 1.017073555899875\n",
      "f1 macro of LFR 0.6601345898286983\n",
      "Disparate Impact of train 0.8461478715459297\n",
      "Disparate Impact of origin 0.7461241809833359\n",
      "f1 macro of origin 0.6675552147462929\n",
      "Disparate Impact of train 1.0000000000000049\n",
      "Disparate Impact of RW 0.7462591549295774\n",
      "f1 macro of RW 0.6682151378580007\n",
      "Disparate Impact of train 0.8461478715459297\n",
      "Disparate Impact of DIremover 0.8552831214931867\n",
      "f1 macro of DIremover 0.6699232671150508\n",
      "Disparate Impact of train 0.951076923076923\n",
      "Disparate Impact of LFR 0.9235246272959393\n",
      "f1 macro of LFR 0.664351308689545\n",
      "Disparate Impact of train 0.8177415382931568\n",
      "Disparate Impact of origin 0.7478431240645128\n",
      "f1 macro of origin 0.6670120668659361\n",
      "Disparate Impact of train 1.0000000000000233\n",
      "Disparate Impact of RW 0.7472873734509206\n",
      "f1 macro of RW 0.6641144965191353\n",
      "Disparate Impact of train 0.8177415382931568\n",
      "Disparate Impact of DIremover 0.846797728477813\n",
      "f1 macro of DIremover 0.6600578457516827\n",
      "Disparate Impact of train 0.9839610445456768\n",
      "Disparate Impact of LFR 0.959694672421376\n",
      "f1 macro of LFR 0.6664156680700997\n",
      "Disparate Impact of train 0.8581902735863058\n",
      "Disparate Impact of origin 0.7876810573750703\n",
      "f1 macro of origin 0.680703769266652\n",
      "Disparate Impact of train 0.9999999999999735\n",
      "Disparate Impact of RW 0.7868029291059789\n",
      "f1 macro of RW 0.6803416201487769\n",
      "Disparate Impact of train 0.8581902735863058\n",
      "Disparate Impact of DIremover 0.8791290039491007\n",
      "f1 macro of DIremover 0.6833909555911635\n",
      "Disparate Impact of train 0.969122049369387\n",
      "Disparate Impact of LFR 0.9954755363993747\n",
      "f1 macro of LFR 0.6785530742057975\n"
     ]
    }
   ],
   "source": [
    "methods=['origin','RW','DIremover','LFR'] \n",
    "report=pd.DataFrame(columns=['DI of train','DI','f1 macro','f1 micro','f1 weighted','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    train,test = cd.split([0.4], shuffle=True) \n",
    "    valid,test = test.split([0.3], shuffle=True)\n",
    "    \n",
    "    prepro = Baselinepreprocess(train,test)\n",
    "    for method in methods:\n",
    "        report = pd.concat([report,prepro.assess(method)], ignore_index=True)\n",
    "\n",
    "report.to_csv(path+'/data/report_preprocess_compas_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path,var_list,pa):\n",
    "    \"\"\"\n",
    "    Load and clean the Adult dataset, and discretize selected attributes \n",
    "    (age, hours-per-week, capital-gain, capital-loss).\n",
    "\n",
    "    Parameters:\n",
    "        data_path (str): Path to the input data file.\n",
    "        var_list (list of str): List of non-protected attribute names.\n",
    "        pa (str): Name of the protected attribute.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned dataset with discretized attributes.\n",
    "    \"\"\"\n",
    "\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education',\n",
    "                'education-num', 'marital-status', 'occupation', 'relationship',\n",
    "                'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                'native-country', 'Y']\n",
    "    na_values=['?']\n",
    "    pa_dict={'Male':1,'Female':0,'White':1,'Black':0}\n",
    "    label_dict={'>50K.':1,'>50K':1,'<=50K.':0,'<=50K':0}\n",
    "    train_path = os.path.join(data_path, 'adult.data')\n",
    "    test_path = os.path.join(data_path, 'adult.test')\n",
    "    train = pd.read_csv(train_path, header=None,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    test = pd.read_csv(test_path, header=0,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    messydata = pd.concat([test, train], ignore_index=True)[var_list+[pa,'Y']]\n",
    "    messydata=messydata.rename(columns={pa:'S'})\n",
    "    messydata['S']=messydata['S'].replace(pa_dict)\n",
    "    messydata['Y']=messydata['Y'].replace(label_dict)\n",
    "    messydata=messydata[(messydata['S']==0)|(messydata['S']==1)]\n",
    "    for col in var_list+['S','Y']:\n",
    "        messydata[col]=messydata[col].astype('int64')\n",
    "    messydata['W']=1\n",
    "\n",
    "    # Define bin thresholds for discretizing attributes.\n",
    "    bins_capitalgain=[100,3500,7500,10000]\n",
    "    bins_capitalloss=[100,1600,1900,2200]\n",
    "    bins_age=[26,36,46,56]\n",
    "    bins_hours=[21,36,46,61]\n",
    "\n",
    "    # Apply discretization to attributes using predefined bins.\n",
    "    messydata=categerise(messydata,'age',bins_age)\n",
    "    messydata=categerise(messydata,'hours-per-week',bins_hours)\n",
    "    messydata=categerise(messydata,'capital-gain',bins_capitalgain)\n",
    "    messydata=categerise(messydata,'capital-loss',bins_capitalloss)\n",
    "    \n",
    "    return messydata\n",
    "\n",
    "def categerise(df,col,bins):\n",
    "    # Apply discretization to attributes using predefined bins.\n",
    "    for i in range(len(bins)+1):\n",
    "        if i == 0:\n",
    "            df.loc[df[col] < bins[i], col] = i\n",
    "        elif i == len(bins):\n",
    "            df.loc[df[col] >= bins[i-1], col] = i\n",
    "        else:\n",
    "            df.loc[(df[col] >= bins[i-1])& (df[col] < bins[i]), col] = i        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_x(var_list,messydata):\n",
    "    \"\"\"\n",
    "    Select non-protected attributes to repair based on their \n",
    "    protected-attribute-wise Total Variation distance.\n",
    "\n",
    "    Attributes are selected if their Total Variation distance exceeds a threshold (default: 0.1).\n",
    "\n",
    "    Parameters:\n",
    "        var_list (list of str): List of non-protected attribute names.\n",
    "        messydata (pd.DataFrame): The cleaned dataset.\n",
    "\n",
    "    Returns:\n",
    "        x_list (list of str): List of non-protected attributes that need to be repaired.\n",
    "        tv_dist (dict): Dictionary mapping each non-protected attribute to its \n",
    "                        protected-attribute-wise Total Variation distance.\n",
    "    \"\"\"\n",
    "\n",
    "    tv_dist=dict()\n",
    "    for x_name in var_list:\n",
    "        x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index) \n",
    "        dist=rdata_analysis(messydata,x_range_single,x_name)\n",
    "        tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "    x_list=[]\n",
    "    for key,val in tv_dist.items():\n",
    "        if val>0.1:\n",
    "            x_list+=[key]  \n",
    "    return x_list,tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='C://Users//zhouq//anaconda3//Lib//site-packages//aif360//data//raw//adult'\n",
    "var_list=['hours-per-week','age','capital-gain','capital-loss','education-num'] #,'education-num'\n",
    "pa='race'\n",
    "favorable_label = 1\n",
    "var_dim=len(var_list)\n",
    "\n",
    "messydata = load_data(data_path,var_list,pa)\n",
    "x_list,tv_dist = choose_x(var_list,messydata)\n",
    "messydata=messydata.rename(columns={'S':pa})\n",
    "cd=BinaryLabelDataset(\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0,\n",
    "    df=messydata,label_names='Y',protected_attribute_names=[pa])\n",
    "# train,test = cd.split([0.4], shuffle=True) \n",
    "# valid,test = test.split([0.3], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.4423024479779176\n",
      "Disparate Impact of origin 0.4761241484554046\n",
      "f1 macro of origin 0.6696624107858051\n",
      "Disparate Impact of train 0.9999999999998899\n",
      "Disparate Impact of RW 0.46521121614598077\n",
      "f1 macro of RW 0.6779482632516027\n",
      "Disparate Impact of train 0.4423024479779176\n",
      "Disparate Impact of DIremover 0.4754678848427709\n",
      "f1 macro of DIremover 0.6761039218256115\n",
      "Disparate Impact of train 0.8188911000561955\n",
      "Disparate Impact of LFR 0.8403672932237478\n",
      "f1 macro of LFR 0.6921478761007314\n",
      "Disparate Impact of train 0.45067826635145786\n",
      "Disparate Impact of origin 0.49080822521331785\n",
      "f1 macro of origin 0.6820805989657579\n",
      "Disparate Impact of train 1.0000000000003044\n",
      "Disparate Impact of RW 0.48527679623085984\n",
      "f1 macro of RW 0.6765581603975014\n",
      "Disparate Impact of train 0.45067826635145786\n",
      "Disparate Impact of DIremover 0.4790061250933923\n",
      "f1 macro of DIremover 0.6799367478843286\n",
      "Disparate Impact of train 0.7768607938615907\n",
      "Disparate Impact of LFR 0.7838645991916943\n",
      "f1 macro of LFR 0.6852461845853519\n",
      "Disparate Impact of train 0.4619546191214598\n",
      "Disparate Impact of origin 0.45637323184961964\n",
      "f1 macro of origin 0.6749153401155569\n",
      "Disparate Impact of train 0.999999999999862\n",
      "Disparate Impact of RW 0.4645428150976415\n",
      "f1 macro of RW 0.67427439322347\n",
      "Disparate Impact of train 0.4619546191214598\n",
      "Disparate Impact of DIremover 0.4744699337628779\n",
      "f1 macro of DIremover 0.6760720119892479\n",
      "Disparate Impact of train 0.7925409089084856\n",
      "Disparate Impact of LFR 0.7940217108163985\n",
      "f1 macro of LFR 0.6889898624647122\n",
      "Disparate Impact of train 0.4896358346382201\n",
      "Disparate Impact of origin 0.3867278866764607\n",
      "f1 macro of origin 0.6812181376260478\n",
      "Disparate Impact of train 1.0000000000001594\n",
      "Disparate Impact of RW 0.3946254212922438\n",
      "f1 macro of RW 0.6609939589700606\n",
      "Disparate Impact of train 0.4896358346382201\n",
      "Disparate Impact of DIremover 0.3703514200926873\n",
      "f1 macro of DIremover 0.6736112419193034\n",
      "Disparate Impact of train 0.8166565986367389\n",
      "Disparate Impact of LFR 0.7976567418146462\n",
      "f1 macro of LFR 0.6945838879009869\n",
      "Disparate Impact of train 0.514807684214956\n",
      "Disparate Impact of origin 0.42534165413511005\n",
      "f1 macro of origin 0.679942723053309\n",
      "Disparate Impact of train 0.9999999999997609\n",
      "Disparate Impact of RW 0.43376412814795473\n",
      "f1 macro of RW 0.6808140780641915\n",
      "Disparate Impact of train 0.514807684214956\n",
      "Disparate Impact of DIremover 0.43034823450619886\n",
      "f1 macro of DIremover 0.6797014306799523\n",
      "Disparate Impact of train 0.8750772481262185\n",
      "Disparate Impact of LFR 0.8120135018199436\n",
      "f1 macro of LFR 0.6964399440357925\n",
      "Disparate Impact of train 0.46519164517648554\n",
      "Disparate Impact of origin 0.5087143047475241\n",
      "f1 macro of origin 0.6813857495114106\n",
      "Disparate Impact of train 0.9999999999999366\n",
      "Disparate Impact of RW 0.5216105343124842\n",
      "f1 macro of RW 0.6888684604410261\n",
      "Disparate Impact of train 0.46519164517648554\n",
      "Disparate Impact of DIremover 0.5077117744469449\n",
      "f1 macro of DIremover 0.6883610276168922\n",
      "Disparate Impact of train 0.8008620689655173\n",
      "Disparate Impact of LFR 0.9110297514393078\n",
      "f1 macro of LFR 0.696705989443378\n",
      "Disparate Impact of train 0.45173184380302833\n",
      "Disparate Impact of origin 0.5224055777822585\n",
      "f1 macro of origin 0.6820145663333177\n",
      "Disparate Impact of train 1.0000000000001483\n",
      "Disparate Impact of RW 0.5091016207993702\n",
      "f1 macro of RW 0.689224309608689\n",
      "Disparate Impact of train 0.45173184380302833\n",
      "Disparate Impact of DIremover 0.5105015802585955\n",
      "f1 macro of DIremover 0.6811543048985529\n",
      "Disparate Impact of train 0.7309188810569225\n",
      "Disparate Impact of LFR 0.8507213216443911\n",
      "f1 macro of LFR 0.6978326509408188\n",
      "Disparate Impact of train 0.47968053176107783\n",
      "Disparate Impact of origin 0.41728772434546096\n",
      "f1 macro of origin 0.6759675778329068\n",
      "Disparate Impact of train 1.000000000000237\n",
      "Disparate Impact of RW 0.40926739092722697\n",
      "f1 macro of RW 0.6706892818235476\n",
      "Disparate Impact of train 0.47968053176107783\n",
      "Disparate Impact of DIremover 0.4065249606372141\n",
      "f1 macro of DIremover 0.6726831996052693\n",
      "Disparate Impact of train 0.9357545473220625\n",
      "Disparate Impact of LFR 0.8834083906843397\n",
      "f1 macro of LFR 0.6862595325893764\n",
      "Disparate Impact of train 0.45553290296844845\n",
      "Disparate Impact of origin 0.5076748142507296\n",
      "f1 macro of origin 0.6867406474491867\n",
      "Disparate Impact of train 1.0000000000001756\n",
      "Disparate Impact of RW 0.5280251454891369\n",
      "f1 macro of RW 0.6644919853251716\n",
      "Disparate Impact of train 0.45553290296844845\n",
      "Disparate Impact of DIremover 0.5119918781476149\n",
      "f1 macro of DIremover 0.682850353667898\n",
      "Disparate Impact of train 0.7145153256604923\n",
      "Disparate Impact of LFR 0.7375479655596388\n",
      "f1 macro of LFR 0.6954052688016314\n",
      "Disparate Impact of train 0.4579237489947454\n",
      "Disparate Impact of origin 0.6098994252873563\n",
      "f1 macro of origin 0.6787992297553438\n",
      "Disparate Impact of train 0.9999999999999943\n",
      "Disparate Impact of RW 0.6019130494247176\n",
      "f1 macro of RW 0.6853698684940933\n",
      "Disparate Impact of train 0.4579237489947454\n",
      "Disparate Impact of DIremover 0.6288973665691321\n",
      "f1 macro of DIremover 0.6755356785218325\n",
      "Disparate Impact of train 0.7569330629685916\n",
      "Disparate Impact of LFR 0.9359070464767616\n",
      "f1 macro of LFR 0.6901917069488299\n"
     ]
    }
   ],
   "source": [
    "methods=['origin','RW','DIremover','LFR'] \n",
    "report=pd.DataFrame(columns=['DI of train','DI','f1 macro','f1 micro','f1 weighted','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    train,test = cd.split([0.4], shuffle=True) \n",
    "    valid,test = test.split([0.3], shuffle=True)\n",
    "    \n",
    "    prepro = Baselinepreprocess(train,test)\n",
    "    for method in methods:\n",
    "        report = pd.concat([report,prepro.assess(method)], ignore_index=True)\n",
    "\n",
    "report.to_csv(path+'/data/report_preprocess_adult_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI of train</th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.442302</td>\n",
       "      <td>0.476124</td>\n",
       "      <td>0.669662</td>\n",
       "      <td>0.812599</td>\n",
       "      <td>0.782036</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.465211</td>\n",
       "      <td>0.677948</td>\n",
       "      <td>0.814598</td>\n",
       "      <td>0.786436</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.442302</td>\n",
       "      <td>0.475468</td>\n",
       "      <td>0.676104</td>\n",
       "      <td>0.814035</td>\n",
       "      <td>0.785411</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.818891</td>\n",
       "      <td>0.840367</td>\n",
       "      <td>0.692148</td>\n",
       "      <td>0.808294</td>\n",
       "      <td>0.789936</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.450678</td>\n",
       "      <td>0.490808</td>\n",
       "      <td>0.682081</td>\n",
       "      <td>0.816341</td>\n",
       "      <td>0.787928</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.485277</td>\n",
       "      <td>0.676558</td>\n",
       "      <td>0.815162</td>\n",
       "      <td>0.785034</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.450678</td>\n",
       "      <td>0.479006</td>\n",
       "      <td>0.679937</td>\n",
       "      <td>0.815316</td>\n",
       "      <td>0.786582</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.776861</td>\n",
       "      <td>0.783865</td>\n",
       "      <td>0.685246</td>\n",
       "      <td>0.807268</td>\n",
       "      <td>0.785651</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.461955</td>\n",
       "      <td>0.456373</td>\n",
       "      <td>0.674915</td>\n",
       "      <td>0.810088</td>\n",
       "      <td>0.780571</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464543</td>\n",
       "      <td>0.674274</td>\n",
       "      <td>0.810036</td>\n",
       "      <td>0.780265</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.461955</td>\n",
       "      <td>0.47447</td>\n",
       "      <td>0.676072</td>\n",
       "      <td>0.810293</td>\n",
       "      <td>0.781168</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.792541</td>\n",
       "      <td>0.794022</td>\n",
       "      <td>0.68899</td>\n",
       "      <td>0.808294</td>\n",
       "      <td>0.786078</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.489636</td>\n",
       "      <td>0.386728</td>\n",
       "      <td>0.681218</td>\n",
       "      <td>0.815419</td>\n",
       "      <td>0.787482</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.394625</td>\n",
       "      <td>0.660994</td>\n",
       "      <td>0.811779</td>\n",
       "      <td>0.777151</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.489636</td>\n",
       "      <td>0.370351</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.813522</td>\n",
       "      <td>0.783399</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.816657</td>\n",
       "      <td>0.797657</td>\n",
       "      <td>0.694584</td>\n",
       "      <td>0.807781</td>\n",
       "      <td>0.790111</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.514808</td>\n",
       "      <td>0.425342</td>\n",
       "      <td>0.679943</td>\n",
       "      <td>0.817828</td>\n",
       "      <td>0.790283</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.433764</td>\n",
       "      <td>0.680814</td>\n",
       "      <td>0.818238</td>\n",
       "      <td>0.79082</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.514808</td>\n",
       "      <td>0.430348</td>\n",
       "      <td>0.679701</td>\n",
       "      <td>0.818186</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.875077</td>\n",
       "      <td>0.812014</td>\n",
       "      <td>0.69644</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.795396</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.465192</td>\n",
       "      <td>0.508714</td>\n",
       "      <td>0.681386</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.78851</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.521611</td>\n",
       "      <td>0.688868</td>\n",
       "      <td>0.817315</td>\n",
       "      <td>0.792517</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.465192</td>\n",
       "      <td>0.507712</td>\n",
       "      <td>0.688361</td>\n",
       "      <td>0.817366</td>\n",
       "      <td>0.79232</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.800862</td>\n",
       "      <td>0.91103</td>\n",
       "      <td>0.696706</td>\n",
       "      <td>0.80978</td>\n",
       "      <td>0.792722</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.451732</td>\n",
       "      <td>0.522406</td>\n",
       "      <td>0.682015</td>\n",
       "      <td>0.818238</td>\n",
       "      <td>0.790436</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.509102</td>\n",
       "      <td>0.689224</td>\n",
       "      <td>0.820903</td>\n",
       "      <td>0.794607</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.451732</td>\n",
       "      <td>0.510502</td>\n",
       "      <td>0.681154</td>\n",
       "      <td>0.817981</td>\n",
       "      <td>0.789963</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.730919</td>\n",
       "      <td>0.850721</td>\n",
       "      <td>0.697833</td>\n",
       "      <td>0.8106</td>\n",
       "      <td>0.793995</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.479681</td>\n",
       "      <td>0.417288</td>\n",
       "      <td>0.675968</td>\n",
       "      <td>0.812702</td>\n",
       "      <td>0.783721</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409267</td>\n",
       "      <td>0.670689</td>\n",
       "      <td>0.81183</td>\n",
       "      <td>0.781054</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.479681</td>\n",
       "      <td>0.406525</td>\n",
       "      <td>0.672683</td>\n",
       "      <td>0.811677</td>\n",
       "      <td>0.781873</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.935755</td>\n",
       "      <td>0.883408</td>\n",
       "      <td>0.68626</td>\n",
       "      <td>0.80691</td>\n",
       "      <td>0.785857</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.455533</td>\n",
       "      <td>0.507675</td>\n",
       "      <td>0.686741</td>\n",
       "      <td>0.819263</td>\n",
       "      <td>0.793049</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.528025</td>\n",
       "      <td>0.664492</td>\n",
       "      <td>0.81547</td>\n",
       "      <td>0.781922</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.455533</td>\n",
       "      <td>0.511992</td>\n",
       "      <td>0.68285</td>\n",
       "      <td>0.818545</td>\n",
       "      <td>0.791089</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.714515</td>\n",
       "      <td>0.737548</td>\n",
       "      <td>0.695405</td>\n",
       "      <td>0.816187</td>\n",
       "      <td>0.795482</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.457924</td>\n",
       "      <td>0.609899</td>\n",
       "      <td>0.678799</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.786639</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.601913</td>\n",
       "      <td>0.68537</td>\n",
       "      <td>0.817008</td>\n",
       "      <td>0.790156</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.457924</td>\n",
       "      <td>0.628897</td>\n",
       "      <td>0.675536</td>\n",
       "      <td>0.814752</td>\n",
       "      <td>0.784968</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.756933</td>\n",
       "      <td>0.935907</td>\n",
       "      <td>0.690192</td>\n",
       "      <td>0.808857</td>\n",
       "      <td>0.788916</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DI of train        DI  f1 macro  f1 micro f1 weighted     method\n",
       "0     0.442302  0.476124  0.669662  0.812599    0.782036     origin\n",
       "1          1.0  0.465211  0.677948  0.814598    0.786436         RW\n",
       "2     0.442302  0.475468  0.676104  0.814035    0.785411  DIremover\n",
       "3     0.818891  0.840367  0.692148  0.808294    0.789936        LFR\n",
       "4     0.450678  0.490808  0.682081  0.816341    0.787928     origin\n",
       "5          1.0  0.485277  0.676558  0.815162    0.785034         RW\n",
       "6     0.450678  0.479006  0.679937  0.815316    0.786582  DIremover\n",
       "7     0.776861  0.783865  0.685246  0.807268    0.785651        LFR\n",
       "8     0.461955  0.456373  0.674915  0.810088    0.780571     origin\n",
       "9          1.0  0.464543  0.674274  0.810036    0.780265         RW\n",
       "10    0.461955   0.47447  0.676072  0.810293    0.781168  DIremover\n",
       "11    0.792541  0.794022   0.68899  0.808294    0.786078        LFR\n",
       "12    0.489636  0.386728  0.681218  0.815419    0.787482     origin\n",
       "13         1.0  0.394625  0.660994  0.811779    0.777151         RW\n",
       "14    0.489636  0.370351  0.673611  0.813522    0.783399  DIremover\n",
       "15    0.816657  0.797657  0.694584  0.807781    0.790111        LFR\n",
       "16    0.514808  0.425342  0.679943  0.817828    0.790283     origin\n",
       "17         1.0  0.433764  0.680814  0.818238     0.79082         RW\n",
       "18    0.514808  0.430348  0.679701  0.818186    0.790323  DIremover\n",
       "19    0.875077  0.812014   0.69644  0.813368    0.795396        LFR\n",
       "20    0.465192  0.508714  0.681386  0.815367     0.78851     origin\n",
       "21         1.0  0.521611  0.688868  0.817315    0.792517         RW\n",
       "22    0.465192  0.507712  0.688361  0.817366     0.79232  DIremover\n",
       "23    0.800862   0.91103  0.696706   0.80978    0.792722        LFR\n",
       "24    0.451732  0.522406  0.682015  0.818238    0.790436     origin\n",
       "25         1.0  0.509102  0.689224  0.820903    0.794607         RW\n",
       "26    0.451732  0.510502  0.681154  0.817981    0.789963  DIremover\n",
       "27    0.730919  0.850721  0.697833    0.8106    0.793995        LFR\n",
       "28    0.479681  0.417288  0.675968  0.812702    0.783721     origin\n",
       "29         1.0  0.409267  0.670689   0.81183    0.781054         RW\n",
       "30    0.479681  0.406525  0.672683  0.811677    0.781873  DIremover\n",
       "31    0.935755  0.883408   0.68626   0.80691    0.785857        LFR\n",
       "32    0.455533  0.507675  0.686741  0.819263    0.793049     origin\n",
       "33         1.0  0.528025  0.664492   0.81547    0.781922         RW\n",
       "34    0.455533  0.511992   0.68285  0.818545    0.791089  DIremover\n",
       "35    0.714515  0.737548  0.695405  0.816187    0.795482        LFR\n",
       "36    0.457924  0.609899  0.678799  0.815367    0.786639     origin\n",
       "37         1.0  0.601913   0.68537  0.817008    0.790156         RW\n",
       "38    0.457924  0.628897  0.675536  0.814752    0.784968  DIremover\n",
       "39    0.756933  0.935907  0.690192  0.808857    0.788916        LFR"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
